{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viC_eDWwyt3v"
   },
   "source": [
    "## Learning to Rank\n",
    "\n",
    "Pointwise: One instance of the set is considered at a time, use any kind of classifier or regressor to predict how relevant it is in the current query. Use each points predicted relevance to order the set.\n",
    "\n",
    "Pairwise: A pair of instances is chosen and the order of those two is predicted. Repeat this for each pair of the query to find the final order of the entire query.\n",
    "\n",
    "Listwise: Many or all instances are considered at once. Try to find the optimal order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxYT1wympZXH"
   },
   "source": [
    "- https://www.kaggle.com/code/prashant111/lightgbm-classifier-in-python\n",
    "- https://www.kaggle.com/code/samratp/lightgbm-xgboost-catboost\n",
    "- https://developer.nvidia.com/blog/learning-to-rank-with-xgboost-and-gpu/#:~:text=XGBoost%20is%20a%20widely%20used,descent%20using%20an%20objective%20function.\n",
    "- https://medium.com/predictly-on-tech/learning-to-rank-using-xgboost-83de0166229d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDXuWhktQRs_",
    "outputId": "e56ee7a8-c717-4bad-bd63-846c11cefdee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting catboost\n",
      "\n",
      "  Downloading catboost-1.0.6-cp38-none-win_amd64.whl (73.9 MB)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from catboost) (1.2.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\anaconda3\\lib\\site-packages (from catboost) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from catboost) (1.20.1)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.8.2-py2.py3-none-any.whl (15.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\anaconda3\\lib\\site-packages (from catboost) (1.15.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20-py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from catboost) (1.6.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (8.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly, graphviz, catboost\n",
      "Successfully installed catboost-1.0.6 graphviz-0.20 plotly-5.8.2 tenacity-8.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "znIW0iF4slqe"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-1925cbaab75b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROB3AoMuy3p1"
   },
   "source": [
    "# Data Preparation (Pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jDVedx--yzk3",
    "outputId": "4b04bbb2-a539-4f8a-b090-e6c947974696"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('hotels3.csv')\n",
    "df.head()\n",
    "df_cp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facilities_columns = ['Food and Drinks','Hotel Services','In-room Facilities', 'Business Facilities', 'Nearby Facilities',\n",
    "                      'Public Facilities', 'General', 'Things to Do', 'Accessibilty', 'Connectivity', 'Transportation',\n",
    "                      'Kids and Pets', 'Sports and Recreations', 'Shuttle Service']\n",
    "ind = []\n",
    "list_subfacil = {}\n",
    "for index, row in df_cp.iterrows():\n",
    "    facils = row['Facil + Akomod'].splitlines()\n",
    "    facils = [facil for facil in facils if facil != '']\n",
    "    \n",
    "    \n",
    "    for facil in facils: \n",
    "        if facil in facilities_columns:\n",
    "            main_facil = facil\n",
    "            list_subfacil[main_facil] = []\n",
    "        else:\n",
    "            list_subfacil[main_facil] += [facil]\n",
    "    ind.append(list_subfacil)\n",
    "\n",
    "# print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, facil in enumerate(ind):\n",
    "    for key, value in facil.items():\n",
    "        df_cp.at[index, \"{}_list\".format(key)] = '\\n'.join(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Food and Drinks_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicti = {'facil' : []}\n",
    "dicti['facil'].append('ha')\n",
    "\n",
    "dicti['facil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "-tIN42w0mZR2"
   },
   "outputs": [],
   "source": [
    "facilities_columns = ['Food and Drinks','Hotel Services','In-room Facilities', 'Business Facilities', 'Nearby Facilities', 'Public Facilities', 'General', 'Things to Do', 'Accessibilty', 'Connectivity', 'Transportation', 'Kids and Pets', 'Sports and Recreations', 'Shuttle Service']\n",
    "\n",
    "facilities_columns.reverse()\n",
    "\n",
    "for index , row in df.iterrows():\n",
    "    \n",
    "    # split per fasil and akomod\n",
    "    arr = row['Facil + Akomod'].splitlines() \n",
    "    arr = [ar for ar in arr if ar != '']\n",
    "    #iterate over fasil and akomod\n",
    "\n",
    "    i = 0\n",
    "    count = 0\n",
    "\n",
    "    for  item in reversed(arr):\n",
    "      count += 1\n",
    "      if item in facilities_columns:\n",
    "        df.at[index,item ] = count-1\n",
    "        count = 0\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.0\n",
       "1     NaN\n",
       "2     1.0\n",
       "3     NaN\n",
       "4     1.0\n",
       "     ... \n",
       "84    1.0\n",
       "85    1.0\n",
       "86    NaN\n",
       "87    1.0\n",
       "88    1.0\n",
       "Name: Shuttle Service, Length: 89, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Shuttle Service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkIBhvf2mcVH"
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7lgszlLmdpg",
    "outputId": "2a4fc79b-1270-42cd-cab3-4d339f084fa2"
   },
   "outputs": [],
   "source": [
    "for index , row in df.iterrows():\n",
    "    \n",
    "    # split per fasil and akomod\n",
    "    arr = row['Places Nearby'].splitlines() \n",
    "    \n",
    "    #iterate over fasil and akomod\n",
    "\n",
    "    i = 0\n",
    "    count = 0\n",
    "    \n",
    "    for ind, item in enumerate(arr):\n",
    "        itemsplits = item.split()\n",
    "        for x in itemsplits:\n",
    "            if x.isdigit():\n",
    "                if itemsplits[1] == \"km\":\n",
    "                    meters = itemsplits[0] * 1000\n",
    "                else:\n",
    "                    meters = itemsplits[0]\n",
    "                    \n",
    "                if meters.isdigit():\n",
    "                    df.at[index,arr[ind-1]] = meters\n",
    "                    #print(meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a19mEMJmgNT",
    "outputId": "54437618-c147-47ea-90a4-637414f7369a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Hotel', 'Star', 'Rating', 'Reviews', 'Harga', 'Places Nearby',\n",
      "       'Facil + Akomod', 'Fast Food', 'Shop & Gifts', 'Business',\n",
      "       'Transportation Hub', 'Casual Dining', 'Nightlife', 'Park & Zoo',\n",
      "       'Public Service', 'Arts & Sciences', 'Fine Dining', 'Sport',\n",
      "       'Quick Bites', 'Education', 'Street Food', 'Activity & Games', 'Cafe',\n",
      "       'Entertainment', 'Food Court', 'Sight & Landmark'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhrIjOXUmjhx"
   },
   "outputs": [],
   "source": [
    "df.Harga = df['Harga'].str.replace('.','', regex = True)\n",
    "df.Harga = df['Harga'].str.replace(',','.', regex = True)\n",
    "df.Harga = df['Harga'].astype(float).astype(int)\n",
    "\n",
    "df.Reviews = df['Reviews'].str.replace('.','', regex = True)\n",
    "df.Reviews = df['Reviews'].str.replace(',','.', regex = True)\n",
    "df.Reviews = df['Reviews'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5cIX6j_mlqG"
   },
   "outputs": [],
   "source": [
    "df = df.fillna(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQpazzsmmnFg"
   },
   "outputs": [],
   "source": [
    "c = df.select_dtypes(object).columns\n",
    "df[c] = df[c].apply(pd.to_numeric,errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgQonygumo0g",
    "outputId": "e70c338d-de92-4b66-9999-0a559448186e"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "YB-E4YjkmrTA",
    "outputId": "ab544a88-7932-43fa-b83b-ae495c884e79"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-CevXm2Q6i1"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0A8fICUnIbP"
   },
   "source": [
    "## Declare feature vector and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wel8athlnWNU",
    "outputId": "402eb9a8-11c0-4672-9c55-b0042af60a9b"
   },
   "outputs": [],
   "source": [
    "# view summary of dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSayjhlNQ_9g"
   },
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmVSKP7YnH-k"
   },
   "outputs": [],
   "source": [
    "X = df[['Star','Reviews','Harga','Shuttle Service','Sports and Recreations', 'Kids and Pets', 'Transportation', 'Connectivity', 'Accessibilty', 'Things to Do', 'General', 'Public Facilities', 'Nearby Facilities', 'Business Facilities', 'In-room Facilities', 'Hotel Services', 'Food and Drinks', 'Fast Food', 'Shop & Gifts', 'Business', 'Transportation Hub', 'Casual Dining', 'Nightlife', 'Park & Zoo', 'Public Service', 'Arts & Sciences', 'Fine Dining', 'Sport', 'Quick Bites', 'Education', 'Street Food', 'Activity & Games', 'Cafe', 'Entertainment', 'Food Court', 'Sight & Landmark' ]]\n",
    "y = df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1ATNg6motGV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "dev_X, val_X, dev_y, val_y = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZB6D4jmvQ0XK"
   },
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHEqGXrQoxuJ"
   },
   "outputs": [],
   "source": [
    "#import lightgbm as lgb\n",
    "#clf = lgb.lambdarank()\n",
    "#clf.fit(X_train, y_train)\n",
    "\n",
    "def run_lgb(X_train, X_test, y_train, y_test):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 40,\n",
    "        \"learning_rate\" : 0.004,\n",
    "        \"bagging_fraction\" : 0.6,\n",
    "        \"feature_fraction\" : 0.6,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbosity\" : -1,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(X, label=y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 5000, \n",
    "                      valid_sets=[lgtrain, lgval], \n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=150, \n",
    "                      evals_result=evals_result)\n",
    "    \n",
    "    #pred_test_y = np.expm1(model.predict(test_X, num_iteration=model.best_iteration))\n",
    "    return model, evals_result #pred_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRD3429DtQXg",
    "outputId": "8ce22738-2868-4d15-e6d8-e600fc8912a8"
   },
   "outputs": [],
   "source": [
    "model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y)\n",
    "print(\"LightGBM Training Completed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zgZvIH5VXlJk",
    "outputId": "99bdfcde-93a8-4014-a237-5aa62b37669d"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "JxUrFaVORP0o",
    "outputId": "5aa1d382-91fa-4e4d-f155-02023794e37b"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# feature importance\n",
    "print(\"Features Importance...\")\n",
    "gain = model.feature_importance('Rating')\n",
    "featureimp = pd.DataFrame({'Rating':model.feature_name(), \n",
    "                   'split':model.feature_importance('split'), \n",
    "                   'Rating':100 * gain / gain.sum()}).sort_values('Rating', ascending=False)\n",
    "print(featureimp[:50])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEiQ4uDssXiD"
   },
   "source": [
    "## XGBoost\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPjhr5ldRK3z"
   },
   "outputs": [],
   "source": [
    "def run_xgb(train_X, train_y, val_X, val_y):\n",
    "    params = {'objective': 'reg:linear', \n",
    "          'eval_metric': 'rmse',\n",
    "          'eta': 0.001,\n",
    "          'max_depth': 10, \n",
    "          'subsample': 0.6, \n",
    "          'colsample_bytree': 0.6,\n",
    "          'alpha':0.001,\n",
    "          'random_state': 42, \n",
    "          'silent': True}\n",
    "    \n",
    "    tr_data = xgb.DMatrix(train_X, train_y)\n",
    "    va_data = xgb.DMatrix(val_X, val_y)\n",
    "    \n",
    "    watchlist = [(tr_data, 'train'), (va_data, 'valid')]\n",
    "    \n",
    "    model_xgb = xgb.train(params, tr_data, 2000, watchlist, maximize=False, early_stopping_rounds = 100, verbose_eval=100)\n",
    "    \n",
    "    #dtest = xgb.DMatrix(test_X)\n",
    "    #xgb_pred_y = np.expm1(model_xgb.predict(dtest, ntree_limit=model_xgb.best_ntree_limit))\n",
    "    \n",
    "    return  model_xgb #, xgb_pred_y,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdWUpwQ6SJWu",
    "outputId": "acf58248-90d1-41b5-adaf-7a8d31b99e83"
   },
   "outputs": [],
   "source": [
    "# Training XGB\n",
    "model_xgb = run_xgb(dev_X, dev_y, val_X, val_y)\n",
    "print(\"XGB Training Completed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tph7rgkYSOjS"
   },
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKXAe9bnSQtM"
   },
   "outputs": [],
   "source": [
    "cb_model = CatBoostRegressor(iterations=500,\n",
    "                             learning_rate=0.05,\n",
    "                             depth=10,\n",
    "                             eval_metric='RMSE',\n",
    "                             random_seed = 42,\n",
    "                             bagging_temperature = 0.2,\n",
    "                             od_type='Iter',\n",
    "                             metric_period = 50,\n",
    "                             od_wait=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_sxznhvSlca",
    "outputId": "f07da1cc-b0e6-4487-cc09-7ce0b05b62e9"
   },
   "outputs": [],
   "source": [
    "cb_model.fit(dev_X, dev_y,\n",
    "             eval_set=(val_X, val_y),\n",
    "             use_best_model=True,\n",
    "             verbose=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7czCy0dSsJo",
    "outputId": "4a2343e0-9b23-4cfa-d050-ed636562de41"
   },
   "source": [
    "pred_test_cat = np.expm1(cb_model.predict(X))\n",
    "print(pred_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPfXvYFmSRsr"
   },
   "source": [
    "## Tensorflow Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Hotel', 'Places Nearby', 'Facil + Akomod'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df\n",
    "df3 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df.loc[:70]\n",
    "test_dataset = df.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('Rating')\n",
    "test_labels = test_features.pop('Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TENSORFLOW PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features))\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = 0.000001\n",
    "dropout = 0\n",
    "schedul = -0.0001\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mikro_model(norm):\n",
    "  \n",
    "    model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(regularizer) ),\n",
    "      layers.Dropout(dropout),\n",
    "      layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "      layers.Dropout(dropout),\n",
    "      layers.Dense(1)\n",
    "      ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def small_model(norm):\n",
    "  \n",
    "    model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(regularizer) ),\n",
    "        layers.Dropout(dropout),\n",
    "      layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "        layers.Dropout(dropout),\n",
    "      layers.Dense(1)\n",
    "      ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def medium_model(norm):\n",
    "  \n",
    "    model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(regularizer) ),\n",
    "      layers.Dropout(dropout),\n",
    "      layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(regularizer) ),\n",
    "      layers.Dropout(dropout),\n",
    "      layers.Dense(1)\n",
    "      ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def large_model(norm):\n",
    "  \n",
    "    model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "        layers.Dropout(dropout),\n",
    "      layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "        layers.Dropout(dropout),\n",
    "      layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "        layers.Dropout(dropout),\n",
    "      layers.Dense(1)\n",
    "      ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def scale_model(norm):\n",
    "  \n",
    "    model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "        layers.Dropout(dropout),\n",
    "      layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "        layers.Dropout(dropout),\n",
    "      layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "        layers.Dropout(dropout),\n",
    "         layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(regularizer)),\n",
    "        layers.Dropout(dropout),\n",
    "      layers.Dense(1)\n",
    "      ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer2 = tf.optimizers.Adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(schedul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_Pipeline (model):\n",
    "    \n",
    "    model.compile(optimizer= optimizer2, loss='mean_absolute_error')\n",
    "    \n",
    "    history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    callbacks = tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "    verbose=0, epochs=100)\n",
    "    \n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    \n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0, 2])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MPG]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    print(hist.tail(10))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = DNN_Pipeline(small_model(normalizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium = DNN_Pipeline(medium_model(normalizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large = DNN_Pipeline(large_model(normalizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mikro = DNN_Pipeline(mikro_model(normalizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = DNN_Pipeline(scale_model(normalizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mikro_predict = mikro.predict(test_features)\n",
    "small_predict = small.predict(test_features)\n",
    "medium_predict = medium.predict(test_features)\n",
    "large_predict = large.predict(test_features)\n",
    "scale_predict = scale.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(mikro_predict,test_labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(small_predict,test_labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(medium_predict,test_labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(large_predict,test_labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(scale_predict,test_labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scale_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medium.predict(train_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANGKING WITH REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "for x in range(1,90):\n",
    "    a.append(x)\n",
    "    \n",
    "print(a)\n",
    "\n",
    "df2 = df\n",
    "df2['Rank'] = a\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df2.loc[:70]\n",
    "test_dataset = df2.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('Rank')\n",
    "test_labels = test_features.pop('Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer2 = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer2.adapt(np.array(train_features))\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large = DNN_Pipeline(large_model(normalizer2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = DNN_Pipeline(scale_model(normalizer2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium = DNN_Pipeline(medium_model(normalizer2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = test_dataset\n",
    "df_rank['score'] = medium.predict(test_features)\n",
    "df_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sorted = df_rank.sort_values(by=['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANk error per item (0 is perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "\n",
    "for x in range (72,90):\n",
    "    b.append(x)\n",
    "\n",
    "    \n",
    "c = b-(new_sorted['Rank'])\n",
    "\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_rank.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank Train Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank train datasets\n",
    "\n",
    "medium.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = train_dataset\n",
    "df_rank['score'] = medium.predict(train_features)\n",
    "df_rank\n",
    "new_sorted2 = df_rank.sort_values(by=['score'])\n",
    "new_sorted2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANk error per item (0 is perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = []\n",
    "\n",
    "for x in range (1,72):\n",
    "    K.append(x)\n",
    "\n",
    "    \n",
    "c = K-(new_sorted2['Rank'])\n",
    "\n",
    "for x in c:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium.save('TestV1.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "k0A8fICUnIbP",
    "jSayjhlNQ_9g",
    "BPfXvYFmSRsr"
   ],
   "name": "Capstone - Test  v2 (XGB, LGBM, CB)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
